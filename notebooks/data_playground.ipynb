{
 "cells": [
  {
   "cell_type": "code",
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2025-07-23T21:59:01.389421Z",
     "start_time": "2025-07-23T21:59:01.002946Z"
    }
   },
   "source": [
    "import os\n",
    "import pandas as pd"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T22:03:54.924876Z",
     "start_time": "2025-07-23T22:03:54.920146Z"
    }
   },
   "cell_type": "code",
   "source": [
    "\n",
    "RAW_DIR = os.path.join(\"..\", \"data\", \"raw\")"
   ],
   "id": "71dd517fd8f03a18",
   "outputs": [],
   "execution_count": 5
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T22:04:24.064471Z",
     "start_time": "2025-07-23T22:04:23.817788Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# 1. See exactly what files we have\n",
    "files = os.listdir(RAW_DIR)\n",
    "print(\"Raw files:\", files)\n",
    "\n",
    "# 2. Load each into a DataFrame\n",
    "df_list = []\n",
    "for fname in files:\n",
    "    if fname.lower().endswith(\".csv\"):\n",
    "        path = os.path.join(RAW_DIR, fname)\n",
    "        print(f\"Loading {fname} → shape\", pd.read_csv(path, nrows=5).shape, \"…\")\n",
    "        df = pd.read_csv(path)\n",
    "        df_list.append((fname, df))\n",
    "\n",
    "# 3. Unpack them\n",
    "reddit_df = dict(df_list)[\"Reddit_Data.csv\"]\n",
    "twitter_df = dict(df_list)[\"Twitter_Data.csv\"]\n"
   ],
   "id": "36af4963a70ebcdc",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Raw files: ['Reddit_Data.csv', '.gitkeep', 'Twitter_Data.csv']\n",
      "Loading Reddit_Data.csv → shape (5, 2) …\n",
      "Loading Twitter_Data.csv → shape (5, 2) …\n"
     ]
    }
   ],
   "execution_count": 6
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T22:04:26.983204Z",
     "start_time": "2025-07-23T22:04:26.968520Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"➤ Reddit data:\", reddit_df.shape)\n",
    "display(reddit_df.head())\n",
    "\n",
    "print(\"➤ Twitter data:\", twitter_df.shape)\n",
    "display(twitter_df.head())\n"
   ],
   "id": "9715de7b16ac7c50",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "➤ Reddit data: (37249, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "                                       clean_comment  category\n",
       "0   family mormon have never tried explain them t...         1\n",
       "1  buddhism has very much lot compatible with chr...         1\n",
       "2  seriously don say thing first all they won get...        -1\n",
       "3  what you have learned yours and only yours wha...         0\n",
       "4  for your own benefit you may want read living ...         1"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_comment</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>family mormon have never tried explain them t...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>buddhism has very much lot compatible with chr...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>seriously don say thing first all they won get...</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>what you have learned yours and only yours wha...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>for your own benefit you may want read living ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "➤ Twitter data: (162980, 2)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "                                          clean_text  category\n",
       "0  when modi promised “minimum government maximum...      -1.0\n",
       "1  talk all the nonsense and continue all the dra...       0.0\n",
       "2  what did just say vote for modi  welcome bjp t...       1.0\n",
       "3  asking his supporters prefix chowkidar their n...       1.0\n",
       "4  answer who among these the most powerful world...       1.0"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>clean_text</th>\n",
       "      <th>category</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>when modi promised “minimum government maximum...</td>\n",
       "      <td>-1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>talk all the nonsense and continue all the dra...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>what did just say vote for modi  welcome bjp t...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>asking his supporters prefix chowkidar their n...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>answer who among these the most powerful world...</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T22:05:26.279015Z",
     "start_time": "2025-07-23T22:05:26.237761Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(\"Reddit info:\")\n",
    "display(reddit_df.info())\n",
    "print(\"Missing in Reddit:\")\n",
    "display(reddit_df.isna().sum())\n",
    "\n",
    "print(\"\\nTwitter info:\")\n",
    "display(twitter_df.info())\n",
    "print(\"Missing in Twitter:\")\n",
    "display(twitter_df.isna().sum())\n"
   ],
   "id": "549497c80761397f",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Reddit info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 37249 entries, 0 to 37248\n",
      "Data columns (total 2 columns):\n",
      " #   Column         Non-Null Count  Dtype \n",
      "---  ------         --------------  ----- \n",
      " 0   clean_comment  37149 non-null  object\n",
      " 1   category       37249 non-null  int64 \n",
      "dtypes: int64(1), object(1)\n",
      "memory usage: 582.1+ KB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing in Reddit:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "clean_comment    100\n",
       "category           0\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Twitter info:\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 162980 entries, 0 to 162979\n",
      "Data columns (total 2 columns):\n",
      " #   Column      Non-Null Count   Dtype  \n",
      "---  ------      --------------   -----  \n",
      " 0   clean_text  162976 non-null  object \n",
      " 1   category    162973 non-null  float64\n",
      "dtypes: float64(1), object(1)\n",
      "memory usage: 2.5+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Missing in Twitter:\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "clean_text    4\n",
       "category      7\n",
       "dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T22:07:40.816726Z",
     "start_time": "2025-07-23T22:07:40.746504Z"
    }
   },
   "cell_type": "code",
   "source": [
    "# --- Harmonize column names ---\n",
    "# Rename Twitter’s column to match Reddit’s\n",
    "twitter_df = twitter_df.rename(columns={\"clean_text\": \"clean_comment\"})\n",
    "\n",
    "# Ensure category is integer in both\n",
    "reddit_df[\"category\"]  = reddit_df[\"category\"].astype(int)\n",
    "twitter_df[\"category\"] = twitter_df[\"category\"].fillna(-1).astype(int)\n",
    "\n",
    "# --- Combine and inspect again ---\n",
    "df_all = pd.concat([reddit_df, twitter_df], ignore_index=True)\n",
    "print(\"Combined shape before clean:\", df_all.shape)\n",
    "\n",
    "# --- Drop rows with missing or placeholder labels ---\n",
    "# Here we treat category==-1 (from NaNs) as missing\n",
    "df_all = df_all[df_all[\"category\"] >= 0]\n",
    "print(\"After removing missing labels:\", df_all.shape)\n",
    "\n",
    "# --- Drop any rows with missing text ---\n",
    "df_all = df_all.dropna(subset=[\"clean_comment\"])\n",
    "print(\"After dropna text:\", df_all.shape)\n",
    "\n",
    "# --- Optional: drop exact duplicates of text  ---\n",
    "before_dupe = len(df_all)\n",
    "df_all = df_all.drop_duplicates(subset=[\"clean_comment\"])\n",
    "print(f\"Dropped {before_dupe - len(df_all)} duplicate rows; now {len(df_all)} rows\")\n",
    "\n",
    "# Inspect label balance\n",
    "display(df_all[\"category\"].value_counts())\n"
   ],
   "id": "7ea75ec587908b3a",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Combined shape before clean: (200229, 2)\n",
      "After removing missing labels: (156435, 2)\n",
      "After dropna text: (156332, 2)\n",
      "Dropped 379 duplicate rows; now 155953 rows\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "category\n",
       "1    87992\n",
       "0    67961\n",
       "Name: count, dtype: int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "execution_count": 9
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2025-07-23T22:08:55.535317Z",
     "start_time": "2025-07-23T22:08:55.274678Z"
    }
   },
   "cell_type": "code",
   "source": [
    "out_fp = os.path.join(\"..\", \"data\", \"processed\", \"cleaned_data.csv\")\n",
    "df_all.to_csv(out_fp, index=False)\n",
    "print(\"Saved cleaned data to\", out_fp)\n"
   ],
   "id": "828eb0c44b7b4e48",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved cleaned data to ../data/processed/cleaned_data.csv\n"
     ]
    }
   ],
   "execution_count": 10
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": "",
   "id": "75f71f84dc17f20b"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
